{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CrjZ-Ma78a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.0.0-py3-none-any.whl (715 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.6/715.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/site-packages (from pytorch_lightning) (1.24.2)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.0.0-cp311-none-macosx_10_9_x86_64.whl (139.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m851.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/site-packages (from pytorch_lightning) (6.0)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/site-packages (from pytorch_lightning) (23.0)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting lightning-utilities>=0.7.0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl (355 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.1/355.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.10.7-py3-none-any.whl (10 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp311-cp311-macosx_10_9_x86_64.whl (59 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp311-cp311-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, tqdm, sympy, networkx, multidict, fsspec, frozenlist, filelock, async-timeout, yarl, torch, lightning-utilities, aiosignal, torchmetrics, aiohttp, pytorch_lightning\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 filelock-3.10.7 frozenlist-1.3.3 fsspec-2023.3.0 lightning-utilities-0.8.0 mpmath-1.3.0 multidict-6.0.4 networkx-3.0 pytorch_lightning-2.0.0 sympy-1.11.1 torch-2.0.0 torchmetrics-0.11.4 tqdm-4.65.0 typing-extensions-4.5.0 yarl-1.8.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m172.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m554.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorboardX) (1.24.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorboardX) (23.0)\n",
      "Collecting protobuf<4,>=3.8.0\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m280.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m786.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.20.3 tensorboardX-2.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytorch_lightning\n",
    "!pip3 install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1CmEukeg8Njd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboardX\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtb\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "import tensorboardX as tb\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4cLf0zW8Njf"
   },
   "source": [
    "## Create pairs (first track, subsequent track, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "DHUIFjU0Z09C"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKlgAqq-8Njg"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/drive/MyDrive/recsys-mobod-2022/seminar_05/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9aeehkP8Njh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(DATA_DIR + \"data.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj9JftT88Njh"
   },
   "outputs": [],
   "source": [
    "Pair = namedtuple(\"Session\", [\"user\", \"start\", \"track\", \"time\"])\n",
    "\n",
    "def get_pairs(user_data):\n",
    "    pairs = []\n",
    "    first = None\n",
    "    for _, row in user_data.sort_values(\"timestamp\").iterrows():\n",
    "        if first is None:\n",
    "            first = row[\"track\"]\n",
    "        else:\n",
    "            pairs.append(Pair(row[\"user\"], first, row[\"track\"], row[\"time\"]))\n",
    "        \n",
    "        if row[\"message\"] == \"last\":\n",
    "            first = None\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c_Ifi9_8Nji"
   },
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame(\n",
    "    data\n",
    "    .groupby(\"user\")\n",
    "    .apply(get_pairs)\n",
    "    .explode()\n",
    "    .values\n",
    "    .tolist(),\n",
    "    columns=[\"user\", \"start\", \"track\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA0LzG3Z8Nji"
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "sns.histplot(pairs[\"time\"], ax=ax)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkYDflFK8Njj"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE63YQAi8Njj"
   },
   "outputs": [],
   "source": [
    "rdm = np.random.random(len(pairs))\n",
    "train_data = pairs[rdm < 0.8]\n",
    "val_data = pairs[(rdm >= 0.8) & (rdm < 0.9)]\n",
    "test_data = pairs[rdm >= 0.9]\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qevMteNvrHUa"
   },
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N72w3Ym8Njl"
   },
   "outputs": [],
   "source": [
    "class ContextualRanker(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim=10):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # We won't have embeddings for everything, but that's ok\n",
    "        self.context = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "        self.track = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = self.context(x[:, 0])\n",
    "        track = self.track(x[:, 1])\n",
    "        return torch.sum(context * track, dim=1)\n",
    "            \n",
    "    def step(self, batch, batch_idx, metric, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = F.mse_loss(predictions, y.float(), reduction='mean')\n",
    "        self.log(metric, loss, prog_bar=prog_bar)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        avgs = y[:, 0].float()\n",
    "        targets = y[:, 1].float()\n",
    "        rdms = y[:, 2].float()\n",
    "\n",
    "        loss = F.mse_loss(predictions, targets, reduction='mean')\n",
    "        avg_loss = F.mse_loss(avgs, targets, reduction='mean')\n",
    "        rdm_loss = F.mse_loss(rdms, targets, reduction='mean')\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=prog_bar)\n",
    "        self.log(\"avg_loss\", avg_loss, prog_bar=prog_bar)\n",
    "        self.log(\"rdm_loss\", rdm_loss, prog_bar=prog_bar)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train_loss\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val_loss\", True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "        scheduler = {\n",
    "            'scheduler': lr_scheduler,\n",
    "            'reduce_on_plateau': True,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSZTEW7h9d3p"
   },
   "outputs": [],
   "source": [
    "class ContextualRankerData(pl.LightningDataModule):\n",
    "  def __init__(self, train_data, val_data, test_data, features):\n",
    "      super().__init__()\n",
    "      self.train_data = train_data\n",
    "      self.val_data = val_data\n",
    "      self.test_data = test_data\n",
    "      self.features = features\n",
    "\n",
    "  def prepare_data(self):\n",
    "      self.test_data = self.test_data.assign(rdm = np.random.random(len(self.test_data))).assign(avg = self.train_data[\"time\"].mean())\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "      if stage == \"fit\" or stage is None:\n",
    "        self.train_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.train_data[self.features].values), \n",
    "            torch.from_numpy(self.train_data[\"time\"].values)\n",
    "            )\n",
    "\n",
    "        self.val_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.val_data[self.features].values), \n",
    "            torch.from_numpy(self.val_data[\"time\"].values)\n",
    "            )\n",
    "        \n",
    "      if stage == \"test\" or stage is None:  \n",
    "        self.test_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.test_data[self.features].values),\n",
    "            torch.from_numpy(self.test_data[[\"time\", \"avg\", \"rdm\"]].values)\n",
    "        )\n",
    "  def train_dataloader(self):\n",
    "      return td.DataLoader(self.train_dataset, batch_size=2048, shuffle=True, num_workers=0)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return td.DataLoader(self.val_dataset, batch_size=2048, num_workers=0)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "      return td.DataLoader(self.test_dataset, batch_size=512, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWZ8cqTZ8Njm"
   },
   "outputs": [],
   "source": [
    "net = ContextualRanker(embedding_dim=100)\n",
    "data_module = ContextualRankerData(train_data, val_data, test_data, features = [\"start\", \"track\"])\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omCmoxVhGfJ2"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/lightning_logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sqy8qDr98Njm"
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    net, \n",
    "    data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IeB7jzb8Njn"
   },
   "outputs": [],
   "source": [
    "best = ContextualRanker.load_from_checkpoint(checkpoint_callback.best_model_path, embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTUgc8_hQ7N0"
   },
   "outputs": [],
   "source": [
    "trainer.test(best, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRZLUR9_8Njo"
   },
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UrLSjgt8Njo"
   },
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqwVsVyO8Njp"
   },
   "outputs": [],
   "source": [
    "context_embeddings = dict(best.named_parameters())[\"context.weight\"].data.cpu().numpy()\n",
    "track_embeddings = dict(best.named_parameters())[\"track.weight\"].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z1VTPGh8Njp"
   },
   "outputs": [],
   "source": [
    "track_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7_A20no8Njp"
   },
   "outputs": [],
   "source": [
    "k = 100\n",
    "with open(DATA_DIR + \"tracks_with_recs.json\", \"w\") as rf:\n",
    "    for _, track in tqdm.tqdm(track_meta.iterrows()):\n",
    "        embedding = context_embeddings[track[\"track\"]]\n",
    "        neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "        \n",
    "        recommendation = dict(track)\n",
    "        recommendation[\"recommendations\"] = neighbours.tolist()\n",
    "        \n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhS_o_ff8Njp"
   },
   "outputs": [],
   "source": [
    "track = 3916\n",
    "embedding = context_embeddings[track]\n",
    "track_meta.loc[track_meta[\"track\"] == track, [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGFHEN8g8Njq"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "track_meta.loc[track_meta[\"track\"].isin(neighbours), [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymCblQht8Njq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
